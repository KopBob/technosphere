{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from find_duplicates import find_duplicates, dataset2sketches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.path.split('./dataset/dump_part004.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with gzip.open('./dataset/dump_part004.gz', 'rb') as f:\n",
    "    buffer = cStringIO.StringIO(f.read())\n",
    "    reader = DocumentStreamReader(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath = \"./dataset/\"\n",
    "\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "onlyfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "times = []\n",
    "for f in onlyfiles:\n",
    "    s = time.time()\n",
    "    dataset2sketches('./dataset/%s' % f)\n",
    "    t = time.time() - s\n",
    "    print t, f\n",
    "    times.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from find_duplicates import find_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "find_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "mypath = \"./csvs/\"\n",
    "\n",
    "csvs_files = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "csvs_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.concat([pd.read_csv(\"./csvs/%s\" % f, index_col=0) for f in csvs_files])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "ids = find_duplicates(df)\n",
    "print time.time() - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from find_duplicates import list2comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "ids_pairs = ids.apply(list2comb).to\n",
    "print time.time() - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_pairs = reduce(lambda res, x: res + x, ids_pairs, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = 5\n",
    "N= 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_df.to_csv(\"result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mmh3\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "from src.docreader import DocumentStreamReader\n",
    "from src.htmlparse import parse_html\n",
    "\n",
    "import gzip\n",
    "import cStringIO\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def words2shingles(words, W=5):\n",
    "    return set([\" \".join(words[i:i + W]) for i in range(0, len(words) - W)])\n",
    "\n",
    "def minhashing(items, N=20):\n",
    "    dictionary = defaultdict(list)\n",
    "    for item in items:\n",
    "        h = mmh3.hash(item)\n",
    "        dictionary[h % N].append(h)\n",
    "    minihashes = {k:sorted(set(v)) for k,v in dictionary.items()}\n",
    "    return [v[0] for k,v in minihashes.items() if len(v) > 0]    \n",
    "\n",
    "def doc2scratch(doc):\n",
    "    words = parse_html(doc.body).encode(\"utf8\").split(\" \")\n",
    "    shingles = words2shingles(words)\n",
    "    \n",
    "    sketch = minhashing(shingles)\n",
    "    \n",
    "    return pd.DataFrame(zip([doc.url]*len(sketch), sketch), columns=[\"id\", \"sketch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with gzip.open('./dataset/dump_part004.gz', 'rb') as f:\n",
    "    buffer = cStringIO.StringIO(f.read())\n",
    "    reader = DocumentStreamReader(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([])\n",
    "for i, doc in enumerate(reader):\n",
    "    scratch_df = doc2scratch(doc)\n",
    "    df = pd.concat([df, scratch_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list2comb(x):\n",
    "    return list(itertools.combinations(sorted(x), 2))\n",
    "\n",
    "def find_duplicates(data_df):\n",
    "    grouped = df.groupby([\"sketch\"])\n",
    "    common = grouped.aggregate(lambda x: set(x))\n",
    "    common[\"size\"] = common[\"id\"].apply(lambda x: len(x))\n",
    "    ids = common[common[\"size\"] > 1][\"id\"]\n",
    "    \n",
    "    ids_pairs = ids.apply(list2comb).tolist()\n",
    "    \n",
    "    all_pairs = reduce(lambda res, x: res+x, ids_pairs, [])\n",
    "    counter = Counter(all_pairs)\n",
    "    pairs, counts = zip(*counter.most_common())\n",
    "    counts = np.array(counts)\n",
    "    ratio = counts/float(np.max(counts))\n",
    "    print np.max(counts)\n",
    "    print ratio[:100]\n",
    "    for p in pairs[:100]:\n",
    "        print p[0], p[1]\n",
    "#     print len(all_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "find_duplicates(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
