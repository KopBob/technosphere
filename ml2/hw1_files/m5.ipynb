{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ДЗ1 \n",
    "#### Реализация модельного дерева решений с линейной регрессией в листьях (задача регрессии)\n",
    "##### Копин Борис Александровч"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://stats.stackexchange.com/questions/78563/regression-tree-algorithm-with-linear-regression-models-in-each-leaf\n",
    "http://stackoverflow.com/questions/11810949/difference-between-regression-tree-and-model-tree\n",
    "http://stats.stackexchange.com/questions/168964/building-a-regression-tree-with-r-from-scratch\n",
    "http://stackoverflow.com/questions/23986164/is-tree-decisiontreeregressor-a-model-tree-or-a-regression-tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[CART](https://github.com/yan9yu/python-books/blob/master/Machine%20Learning/%5BO'Reilly%5D%20-%20Programming%20Collective%20Intelligence.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model trees - http://sci2s.ugr.es/keel/pdf/algorithm/congreso/1992-Quinlan-AI.pdf\n",
    "- - http://download.springer.com/static/pdf/269/art%253A10.1023%252FA%253A1007421302149.pdf?originUrl=http%3A%2F%2Flink.springer.com%2Farticle%2F10.1023%2FA%3A1007421302149&token2=exp=1455987988~acl=%2Fstatic%2Fpdf%2F269%2Fart%25253A10.1023%25252FA%25253A1007421302149.pdf%3ForiginUrl%3Dhttp%253A%252F%252Flink.springer.com%252Farticle%252F10.1023%252FA%253A1007421302149*~hmac=d87bfe4b77411a48be24de01de791f2cbf99719ee90a50acd1bc510697804e39\n",
    "- Logistic Model Trees - http://www.cs.waikato.ac.nz/~eibe/pubs/LandwehrHallFrankCameraReady.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/tree.html#tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "a = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class decisionnode:\n",
    "    def __init__(self,col=-1,value=None,results=None,tb=None,fb=None):\n",
    "        self.col=col\n",
    "        self.value=value\n",
    "        self.results=results\n",
    "        self.tb=tb\n",
    "        self.fb=fb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: this can be done by pandas builtin functions\n",
    "# Create counts of possible results (the last column of\n",
    "# each row is the result)\n",
    "def uniquecounts(rows):\n",
    "    results={}\n",
    "    for row in rows:\n",
    "        # The result is the last column\n",
    "        r = row[len(row)-1]\n",
    "        if r not in results:\n",
    "            results[r]=0\n",
    "        results[r]+=1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Divides a set on a specific column. Can handle numeric\n",
    "# or nominal values\n",
    "def divideset(rows, column, value):\n",
    "    # Make a function that tells us if a row is in\n",
    "    # the first group (true) or the second group (false)\n",
    "    split_function = None\n",
    "    if isinstance(value, int) or isinstance(value, float):\n",
    "        split_function = lambda row:row[column] >= value\n",
    "    else:\n",
    "        split_function = lambda row:row[column] == value\n",
    "\n",
    "    # Divide the rows into two sets and return them\n",
    "    set1 = [row for row in rows if split_function(row)]\n",
    "    set2 = [row for row in rows if not split_function(row)]\n",
    "    return (set1, set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Entropy is the sum of p(x)log(p(x)) across all\n",
    "# the different possible results\n",
    "def entropy(rows):\n",
    "    from math import log\n",
    "    log2=lambda x:log(x)/log(2)\n",
    "    results=uniquecounts(rows) # Now calculate the entropy\n",
    "    ent=0.0\n",
    "\n",
    "    for r in results.keys():\n",
    "        p=float(results[r])/len(rows)\n",
    "        ent=ent-p*log2(p)\n",
    "\n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def regscore(rows):\n",
    "    return np.std([row[-1] for row in rows])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The first builds an ordinary decision tree, using as splitting criterion the maximization of the intra-subset variation of the target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def buildtree(rows, scoref=entropy):\n",
    "    if len(rows)==0:\n",
    "        return decisionnode()\n",
    "    \n",
    "    current_score = scoref(rows)\n",
    "    # Set up some variables to track the best criteria\n",
    "    best_gain = 0.0\n",
    "    best_criteria = None\n",
    "    best_sets = None\n",
    "        \n",
    "    column_count = len(rows[0])-1\n",
    "    for col in range(0,column_count):\n",
    "        # Generate the list of different values in\n",
    "        # this column\n",
    "        column_values={}\n",
    "        for row in rows:\n",
    "            column_values[row[col]]=1\n",
    "\n",
    "        # Now try dividing the rows up for each value\n",
    "        # in this column\n",
    "        for value in column_values.keys():\n",
    "            (set1, set2)=divideset(rows, col, value)\n",
    "\n",
    "            # Information gain\n",
    "            p = float(len(set1))/len(rows)\n",
    "            gain = current_score - p*scoref(set1)-(1-p)*scoref(set2)\n",
    "\n",
    "            if gain > best_gain and len(set1) > 0 and len(set2) > 0:\n",
    "                best_gain = gain\n",
    "                best_criteria = (col, value)\n",
    "                best_sets = (set1,set2)\n",
    "\n",
    "    # Create the subbranches\n",
    "    if best_gain > 0:\n",
    "        trueBranch=buildtree(best_sets[0])\n",
    "        falseBranch=buildtree(best_sets[1])\n",
    "        return decisionnode(col=best_criteria[0],\n",
    "                            value=best_criteria[1],\n",
    "                            tb=trueBranch,\n",
    "                            fb=falseBranch)\n",
    "    else:\n",
    "        return decisionnode(results=uniquecounts(rows))\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.]\n",
      " [ 1.  1.  1.]\n",
      " [ 1.  2.  2.]\n",
      " [ 1.  3.  3.]]\n",
      "(4, 3)\n",
      "[-0.95  0.5   0.5 ]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([\n",
    "    [0,0],\n",
    "    [1, 1],\n",
    "    [2, 2],\n",
    "    [3, 3]\n",
    "])\n",
    "y = np.array([-1, 0.2, 0.9, 2.1])\n",
    "\n",
    "\n",
    "X = np.vstack([np.ones(x.shape[0]), x.T]).T\n",
    "print X\n",
    "print X.shape\n",
    "m = np.linalg.lstsq(X, y)[0]\n",
    "print m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model_tree(rows, scoref=entropy):\n",
    "    if len(rows)==0:\n",
    "        return decisionnode()\n",
    "    \n",
    "    current_score = scoref(rows)\n",
    "    # Set up some variables to track the best criteria\n",
    "    best_gain = 0.0\n",
    "    best_criteria = None\n",
    "    best_sets = None\n",
    "        \n",
    "    column_count = len(rows[0])-1\n",
    "    for col in range(0,column_count):\n",
    "        # Generate the list of different values in\n",
    "        # this column\n",
    "        column_values={}\n",
    "        for row in rows:\n",
    "            column_values[row[col]]=1\n",
    "\n",
    "        # Now try dividing the rows up for each value\n",
    "        # in this column\n",
    "        for value in column_values.keys():\n",
    "            (set1, set2)=divideset(rows, col, value)\n",
    "\n",
    "            # Information gain\n",
    "            p = float(len(set1))/len(rows)\n",
    "            gain = current_score - p*scoref(set1)-(1-p)*scoref(set2)\n",
    "\n",
    "            if gain > best_gain and len(set1) > 0 and len(set2) > 0:\n",
    "                best_gain = gain\n",
    "                best_criteria = (col, value)\n",
    "                best_sets = (set1,set2)\n",
    "\n",
    "    # Create the subbranches\n",
    "    if best_gain > 0:\n",
    "        trueBranch=buildtree(best_sets[0])\n",
    "        falseBranch=buildtree(best_sets[1])\n",
    "        return decisionnode(col=best_criteria[0],\n",
    "                            value=best_criteria[1],\n",
    "                            tb=trueBranch,\n",
    "                            fb=falseBranch)\n",
    "    else:\n",
    "        return decisionnode(results=uniquecounts(rows))\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    ['slashdot', 'USA', 'yes', 18, 'None', 120],\n",
    "    ['google', 'France', 'yes', 23, 'Premium', 130],\n",
    "    ['google', 'France', 'yes', 23, 'Premium', 140],\n",
    "    ['google', 'France', 'yes', 23, 'Premium', 120],\n",
    "    ['google', 'France', 'yes', 23, 'Premium', 110],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree = buildtree(data, scoref=regscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.decisionnode instance at 0x1113f9cf8>"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class decisionnode:\n",
    "    def __init__(self, col=-1, value=None, results=None, tb=None, fb=None):\n",
    "        self.col=col\n",
    "        self.value=value\n",
    "        self.results=results\n",
    "        self.tb=tb\n",
    "        self.fb=fb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['slashdot', 'USA', 'yes', 18, 'None', 120]],\n",
       " [['google', 'France', 'yes', 23, 'Premium', 130],\n",
       "  ['google', 'France', 'yes', 23, 'Premium', 140],\n",
       "  ['google', 'France', 'yes', 23, 'Premium', 120],\n",
       "  ['google', 'France', 'yes', 23, 'Premium', 110]])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divideset(data, 1, 'USA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = np.dot(np.dot(np.dot(X_train.T, X_train), X_train.T), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  10.8342,    0.    ,   18.1   ,    0.    ,    0.679 ,    6.782 ,\n",
       "         90.8   ,    1.8195,   24.    ,  666.    ,   20.2   ,   21.57  ,\n",
       "         25.79  ])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import cross_validation as cv\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "housing = datasets.load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./spam.train.txt\", delim_whitespace=True, header=None)\n",
    "y = df.ix[:, 0]\n",
    "X = df.ix[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cv.train_test_split(X.as_matrix(),\n",
    "                                                       y.as_matrix(),\n",
    "                                                       test_size=0.25,\n",
    "                                                       random_state=288)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# INTERNAL\n",
    "# LEAF\n",
    "\n",
    "class Node(object):\n",
    "    def __init__(self, X, y,\n",
    "                 feature_ind=None, value=None,\n",
    "                 tb=None, fb=None, build_model=False):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.tb = tb\n",
    "        self.fb = fb\n",
    "        \n",
    "        self.feature_ind = feature_ind\n",
    "        self.value = value\n",
    "        \n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        \n",
    "        self.weights = None\n",
    "        self.features_ind = set([])\n",
    "        \n",
    "#         if build_model:\n",
    "#             self.fit()\n",
    "        \n",
    "    def fit(self):\n",
    "        self.weights = ols(self.X[:, list(self.features_ind)], self.y)\n",
    "#         if len(self.features_ind):\n",
    "#             self.weights = ols(self.X[:, list(self.features_ind)], self.y)\n",
    "#         else:\n",
    "#             self.weights = ols(self.X, self.y)\n",
    "    \n",
    "    def predict(self, X_pred):\n",
    "        if len(self.features_ind):\n",
    "            return np.dot(X_pred[:, list(self.features_ind)], self.weights)\n",
    "        else:\n",
    "            return np.mean(self.y)\n",
    "        \n",
    "#         if len(self.features_ind):\n",
    "#             return np.dot(X_pred[:, list(self.features_ind)], self.weights)\n",
    "#         print self.weights\n",
    "#         return np.dot(X_pred, self.weights)\n",
    "\n",
    "    @staticmethod\n",
    "    def _error(node):\n",
    "        n = node.X.shape[0]\n",
    "        v = len(node.weights)\n",
    "        deviation_mean = np.sum(np.abs(node.predict(node.X) - node.y))/float(n)\n",
    "        params_norm = (n+v)/(n-v)\n",
    "        return params_norm*deviation\n",
    "        \n",
    "#     @staticmethod\n",
    "#     def _subtree_error(tree):\n",
    "#         if tree.feature_ind:\n",
    "#         else:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Build default tree\n",
    "- Build linear regression in default tree\n",
    "- Estimate error in default tree\n",
    "- Prune tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ols(X, y):\n",
    "    inv = np.linalg.inv(np.dot(X.T, X))\n",
    "    return np.dot(np.dot(inv, X.T), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class m5(object):\n",
    "    def __init__(self, fit_intercept=True, min_samples_leaf=4, sd_ratio=0.05, using_m5=True):\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.sd_ratio = sd_ratio\n",
    "        self.using_m5 = using_m5\n",
    "        \n",
    "        self.tree = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if self.fit_intercept:\n",
    "            X = np.hstack((np.ones((X.shape[0], 1), dtype=X.dtype), X))\n",
    "        # ToDo: Convert nominal to binary\n",
    "        \n",
    "        self.SD = np.std(y)\n",
    "        \n",
    "        self.default_tree = self._build_default_tree(X, y)\n",
    "        \n",
    "#         if self.using_m5:\n",
    "        self.model_tree = self._prune_tree(self.default_tree)\n",
    "        \n",
    "        return self.default_tree\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.fit_intercept:\n",
    "            X = np.hstack((np.ones((X.shape[0], 1), dtype=X.dtype), X))\n",
    "        return np.array([self._tree_predict(x, self.default_tree) for x in X])\n",
    "        \n",
    "    def _tree_predict(self, x, tree):\n",
    "        if not tree.feature_ind:\n",
    "            return tree.predict(x) # np.mean(tree.y)\n",
    "\n",
    "        if x[tree.feature_ind] >= tree.value:\n",
    "            if tree.tb:\n",
    "                return self._tree_predict(x, tree.tb)\n",
    "        else:\n",
    "            if tree.fb:\n",
    "                return self._tree_predict(x, tree.fb)\n",
    "\n",
    "    def _build_default_tree(self, X, y):\n",
    "        # Set up some variables to track the best criteria\n",
    "        if X.shape[0] < 4 or np.std(y) < self.sd_ratio*self.SD:\n",
    "            return Node(X, y)\n",
    "    \n",
    "        best_sdr = 0.0\n",
    "        best_criteria = None\n",
    "        best_split = None\n",
    "\n",
    "        for feature_ind in range(X.shape[1]):\n",
    "            # Generate the list of different values of\n",
    "            # this feature\n",
    "            attr_values = Counter(X[:, feature_ind])\n",
    "\n",
    "            # Compute SDR(Standart Deviation Reduction) http://take.ms/TeWHJ\n",
    "            # for each attr_value\n",
    "            for attr_value in attr_values.keys():\n",
    "                split_ind = X[:, feature_ind] >= attr_value\n",
    "\n",
    "                X_T1, y_T1 = X[split_ind], y[split_ind]\n",
    "                p_T1 = len(y_T1)/float(len(y))\n",
    "\n",
    "                X_T2, y_T2 = X[np.invert(split_ind)], y[np.invert(split_ind)]\n",
    "                p_T2 = len(y_T2)/float(len(y))\n",
    "\n",
    "                sdr = np.std(y) - p_T1*np.std(y_T1) - p_T2*np.std(y_T2)\n",
    "\n",
    "                if sdr > best_sdr and len(y_T1) > 0 and len(y_T2) > 0:\n",
    "                    best_sdr = sdr\n",
    "                    best_criteria = (feature_ind, attr_value)\n",
    "                    best_split = ((X_T1, y_T1), (X_T2, y_T2))\n",
    "                    \n",
    "        T1, T2 = best_split\n",
    "\n",
    "        size_cond = len(T1[1]) < self.min_samples_leaf or len(T2[1]) < self.min_samples_leaf\n",
    "        std_cond = np.std(T1[1]) < self.sd_ratio*self.SD or np.std(T2[1]) < self.sd_ratio*self.SD\n",
    "        \n",
    "        if size_cond or std_cond or best_sdr <= 0: # Leaf node\n",
    "            return Node(X, y)\n",
    "        else: # Create the subbranches\n",
    "#             print \"l\", len(T1[0]), \"r\", len(T2[0])\n",
    "\n",
    "            true_branch = self._build_default_tree(*T1)\n",
    "            false_branch = self._build_default_tree(*T2)\n",
    "            return Node(X, y,\n",
    "                        best_criteria[0], best_criteria[1],\n",
    "                        true_branch, false_branch)\n",
    "\n",
    "    def _prune_tree(self, tree):\n",
    "        self._collect_features(tree)\n",
    "        return tree\n",
    "        \n",
    "    def _collect_features(self, tree):\n",
    "        if not tree.feature_ind:\n",
    "            return set([])\n",
    "\n",
    "        tree.features_ind = self._collect_features(tree.tb) | tree.features_ind\n",
    "        tree.features_ind = self._collect_features(tree.fb) | tree.features_ind\n",
    "\n",
    "        return tree.features_ind | set([tree.feature_ind])\n",
    "\n",
    "    def _subtree_error(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "regressor = m5(using_m5=True)\n",
    "tree = regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.064791941967992178"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.062061657808557477"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "dtr = DecisionTreeRegressor(min_samples_leaf=4)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_pred = dtr.predict(X_test)\n",
    "mean_squared_error(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
