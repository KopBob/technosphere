{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyth.plugins.rtf15.reader import Rtf15Reader\n",
    "from pyth.plugins.plaintext.writer import PlaintextWriter\n",
    "\n",
    "def rtf2text(rtf_content):\n",
    "    fp = io.BytesIO(rtf_content)\n",
    "    doc = Rtf15Reader.read(fp)\n",
    "    fp.close()\n",
    "    return PlaintextWriter.write(doc).getvalue()\n",
    "\n",
    "\n",
    "import docx2txt\n",
    "\n",
    "\n",
    "def doc2text(file_path, doc_content):\n",
    "    tmp_file_path = '/tmp/%d' % hash(file_path)\n",
    "    with open(tmp_file_path, 'w') as ftmp:\n",
    "        ftmp.write(doc_content)\n",
    "        \n",
    "    cmd = ['antiword', tmp_file_path]\n",
    "    p = Popen(cmd, stdout=PIPE)\n",
    "    stdout, stderr = p.communicate()\n",
    "    return stdout\n",
    "\n",
    "\n",
    "import io\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from cStringIO import StringIO\n",
    "\n",
    "def pdf2text(pdf_content):\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    \n",
    "    fp = io.BytesIO(pdf_content)\n",
    "    \n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    password = \"\"\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos=set()\n",
    "\n",
    "    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password,caching=caching, check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "\n",
    "    text = retstr.getvalue()\n",
    "\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## path to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "files_paths = []\n",
    "for root, dirs, files in os.walk(\"../data/\"):\n",
    "    path = root.split('/')\n",
    "\n",
    "    for f in files:\n",
    "        if \"DS_Store\" not in f:\n",
    "            path_to_file = path + [f]\n",
    "            files_paths.append('/'.join(path_to_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect file doctype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#         file_doctype = magic.from_buffer(fin.read(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files_extentions = []\n",
    "files_magic = []\n",
    "files_urls = []\n",
    "\n",
    "\n",
    "# for f in files_paths:\n",
    "    \n",
    "def get_file_info(f):\n",
    "    with open(f, 'r') as fin:\n",
    "        first_line = urllib.unquote(fin.readline())\n",
    "        filename, file_extension = os.path.splitext(first_line.strip())\n",
    "        \n",
    "        if file_extension:\n",
    "            file_extension = file_extension.lower().split('?')[0].strip().split('&')[0].strip()\n",
    "            if \"htm\" in file_extension:\n",
    "                file_extension = \".html\"\n",
    "            if \"php\" in file_extension:\n",
    "                file_extension = \".php\"\n",
    "        \n",
    "#         files_extentions.append(file_extension)\n",
    "        \n",
    "#         files_urls.append(first_line)\n",
    "        \n",
    "        file_magic = magic.from_buffer(fin.read(10000))\n",
    "#         files_magic.append(file_magic)\n",
    "        \n",
    "        return first_line, f, file_extension, file_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "p = mp.Pool()\n",
    "\n",
    "files_info = p.imap(get_file_info, files_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files_df = pd.DataFrame(\n",
    "#     zip(files_urls, files_paths, files_extentions, files_magic),\n",
    "    list(files_info),\n",
    "    columns=[\"url\", \"path\", \"extention\", \"magic\"]\n",
    ")\n",
    "files_df.loc[:, \"doctype\"] = files_df.magic.str.split(',').apply(lambda x: x[0])\n",
    "files_df = files_df.set_index(\"path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27188, 4)\n"
     ]
    }
   ],
   "source": [
    "print(files_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check processed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "onlyfiles = [f for f in listdir(\"../processed/\") if isfile(join(\"../processed/\", f))]\n",
    "processed = ['../data/' + '/'.join(f.replace('html-', '').replace('txt-', '').split('_')) for f in onlyfiles]\n",
    "files_df.loc[files_df.index.isin(processed), \"is_processed\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>extention</th>\n",
       "      <th>magic</th>\n",
       "      <th>doctype</th>\n",
       "      <th>is_processed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>path</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>../data/94/4190889394909492417</th>\n",
       "      <td>http://amb-it.ru/files/orbits_5_manual.pdf\\n</td>\n",
       "      <td>.pdf</td>\n",
       "      <td>PDF document, version 1.5</td>\n",
       "      <td>PDF document</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         url  \\\n",
       "path                                                                           \n",
       "../data/94/4190889394909492417  http://amb-it.ru/files/orbits_5_manual.pdf\\n   \n",
       "\n",
       "                               extention                      magic  \\\n",
       "path                                                                  \n",
       "../data/94/4190889394909492417      .pdf  PDF document, version 1.5   \n",
       "\n",
       "                                     doctype is_processed  \n",
       "path                                                       \n",
       "../data/94/4190889394909492417  PDF document          NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_df[files_df.is_processed != True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "import zlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "not_in_parser =  [\n",
    "    'zlib compressed data',\n",
    "    'Composite Document File V2 Document',\n",
    "    'data',\n",
    "]\n",
    "\n",
    "bs4_parsable_doctypes = [\n",
    "    'HTML document', \n",
    "    'XML 1.0 document',\n",
    "    'XML 1.0 document text',\n",
    "    'ISO-8859 text',\n",
    "    'UTF-8 Unicode text',\n",
    "    'very short file (no magic)',\n",
    "    'XML 1\"  document',\n",
    "    'ASCII text',\n",
    "    'UTF-8 Unicode (with BOM) text',\n",
    "    'PHP script'\n",
    "]\n",
    "\n",
    "pdf2text_doctypes = [\n",
    "    'PDF document'\n",
    "]\n",
    "\n",
    "rtf2text_doctypes = [\n",
    "    'MIME entity',\n",
    "    'Rich Text Format data'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def st0_gen_data_flow(files_df):\n",
    "    for file_path, file_meta in files_df.iterrows():\n",
    "#         if file_path == \"../data/10/949496214207617953\":\n",
    "        if file_meta.is_processed != True:\n",
    "            yield file_path, file_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def st1_read_file(files_flow):\n",
    "    for file_path, file_meta in files_flow:\n",
    "\n",
    "        with open(file_path) as fin:\n",
    "            fin.readline()\n",
    "            file_content = fin.read()\n",
    "            \n",
    "        yield file_path, file_meta, file_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def st2_parse_file(files_flow_with_content_obj):\n",
    "    for file_path, file_meta, file_content in files_flow_with_content:\n",
    "        try:\n",
    "            if file_meta.doctype in pdf2text_doctypes or file_meta.extention == \".pdf\":\n",
    "                yield file_path, file_meta, pdf2text(file_content)\n",
    "\n",
    "            elif file_meta.extention == \".doc\":\n",
    "                yield file_path, file_meta, doc2text(file_content)\n",
    "\n",
    "            elif file_meta.doctype in rtf2text_doctypes:\n",
    "                yield file_path, file_meta, rtf2text(file_content)\n",
    "\n",
    "            elif file_meta.doctype in bs4_parsable_doctypes:\n",
    "                file_bs = BeautifulSoup(file_content, \"html5lib\")\n",
    "                yield file_path, file_meta, file_bs\n",
    "            else:\n",
    "                file_bs = BeautifulSoup(file_content, \"html5lib\")\n",
    "                yield file_path, file_meta, file_bs\n",
    "        except:\n",
    "            msg1 = sys.exc_info()[0]\n",
    "            try:\n",
    "                file_bs = BeautifulSoup(file_content, \"html5lib\")\n",
    "                yield file_path, file_meta, file_bs\n",
    "            except:\n",
    "                msg2 = sys.exc_info()[0]\n",
    "                print(file_path, file_meta.doctype, file_meta.extention, msg1, msg2)\n",
    "                errors[file_path] = [msg1, msg2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import io\n",
    "def st3_save_parsed_file(files_flow_parsed):\n",
    "    for file_path, file_meta, file_parsed in files_flow_parsed:\n",
    "        if isinstance(file_parsed, BeautifulSoup):\n",
    "            file_type = \"html\"\n",
    "            try:\n",
    "                file_text = unicode(file_parsed).encode('utf-8')\n",
    "            except RuntimeError as e:\n",
    "                print(\"RuntimeError\", file_path)\n",
    "                file_text = unicode(file_parsed.get_text()).encode('utf-8')\n",
    "        else:\n",
    "            file_type = \"txt\"\n",
    "            file_text = file_parsed\n",
    "\n",
    "        path_to_parsed_text = (\"../processed/%s-%s_%s\" % (file_type, file_path.split('/')[-2], file_path.split('/')[-1]))\n",
    "        file_text_compressed = zlib.compress(file_text)\n",
    "        \n",
    "        with open(path_to_parsed_text, \"wb\") as myfile:\n",
    "            myfile.write(file_text_compressed)\n",
    "            \n",
    "        yield file_path, file_meta, path_to_parsed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# errors = {}\n",
    "# not_precessed = []\n",
    "\n",
    "# files_flow = st0_gen_data_flow(files_df)\n",
    "# files_flow_with_content = st1_read_file(files_flow)\n",
    "# files_flow_parsed = st2_parse_file(files_flow_with_content)\n",
    "# files_flow_saved = st3_save_parsed_file(files_flow_parsed)\n",
    "# # files_flow_with_parts = st3_extract_document_parts(files_flow_parsed)\n",
    "# # files_main_len = get_main_part_len(files_flow_with_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for i, (file_path, file_meta, path_to_parsed_text) in enumerate(files_flow_saved):\n",
    "#     sys.stdout.write('\\r' + \"%s | %s\" % (i, file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# files_df.is_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# len(to_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import UnicodeDammit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_file(file_data):\n",
    "    file_path, file_meta = file_data\n",
    "\n",
    "    with open(file_path) as fin:\n",
    "        fin.readline()\n",
    "        file_content = fin.read()\n",
    "            \n",
    "    try:\n",
    "        if file_meta.doctype in pdf2text_doctypes or file_meta.extention == \".pdf\":\n",
    "            file_bs = pdf2text(file_content)\n",
    "        elif file_meta.extention == \".doc\":\n",
    "            file_bs = doc2text(file_content)\n",
    "        elif file_meta.doctype in rtf2text_doctypes:\n",
    "            file_bs = rtf2text(file_content)\n",
    "        else: # file_meta.doctype in bs4_parsable_doctypes:\n",
    "            file_bs = BeautifulSoup(file_content, \"html5lib\")\n",
    "            file_bs = file_bs\n",
    "    except:\n",
    "        msg1 = sys.exc_info()[0]\n",
    "        file_bs = BeautifulSoup(file_content, \"html5lib\")\n",
    "        \n",
    "    file_parsed = file_bs\n",
    "\n",
    "    if isinstance(file_parsed, BeautifulSoup):\n",
    "        file_type = \"html\"\n",
    "        try:\n",
    "            file_text = unicode(file_parsed).encode('utf-8')\n",
    "        except RuntimeError as e:\n",
    "            print(\"RuntimeError\", file_path)\n",
    "            file_text = unicode(file_parsed.get_text()).encode('utf-8')\n",
    "    else:\n",
    "        file_type = \"txt\"\n",
    "        file_text = file_parsed\n",
    "\n",
    "    path_to_parsed_text = (\"../processed/%s-%s_%s\" % (file_type, file_path.split('/')[-2], file_path.split('/')[-1]))\n",
    "#     path_to_parsed_text = \"/tmp/parsed\"\n",
    "    file_text_compressed = zlib.compress(file_text)\n",
    "\n",
    "    with open(path_to_parsed_text, \"wb\") as myfile:\n",
    "        myfile.write(file_text_compressed)\n",
    "\n",
    "    return file_path, file_meta, path_to_parsed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_process = [(file_path, file_meta) for file_path, file_meta in files_df.iterrows() if file_meta.is_processed != True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(to_process))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p1 = multiprocessing.Pool(processes=8)\n",
    "\n",
    "mapper_gen = p1.imap_unordered(parse_file, to_process, chunksize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, (file_path, file_meta, path_to_parsed_text) in enumerate(mapper_gen):\n",
    "    sys.stdout.write('\\r' + \"%s | %s\" % (i, file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
