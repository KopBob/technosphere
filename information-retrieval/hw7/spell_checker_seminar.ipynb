{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выполнил**: Копин Борис"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Простой спелчекер:\n",
    "1. Строим словарь из текстов на lenta.ru https://cloud.mail.ru/public/FnMq/qCNif6bFG/all- datasets/samples/sample3/\n",
    "2. Реализуем функцию подсчета расстояния Левенштейна\n",
    "3. Делаем спелчекер с помощью поиска ближайших по Левенштейну слов\n",
    "4. Делаем спелчекер путем генерации ближайших слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = [u\"оцинил\", u\"роботу\", u\"новвых\", u\"самалетав\", u\"и\", u\"виртолтов\", u\"в\", u\"сирийи\",]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH_TO_DATASET = \"./lenta_words.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Строим словарь из текстов на lenta.ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dictionary(path_to_gold):\n",
    "    words = None\n",
    "    with open(path_to_gold, 'r') as f:\n",
    "        words = f.read().splitlines()\n",
    "        \n",
    "    return Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DICTIONARY = load_dictionary(PATH_TO_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "463163"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(DICTIONARY.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_frequent(words):\n",
    "    i_max = 0\n",
    "    max = -1\n",
    "    for i, s in enumerate(words):\n",
    "        if max < DICTIONARY.get(s):\n",
    "            i_max = i\n",
    "            max = DICTIONARY.get(s)\n",
    "    return words[i_max]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Реализуем функцию подсчета расстояния Левенштейна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def levenshtein(s1, s2):\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein(s2, s1)\n",
    "\n",
    "    # len(s1) >= len(s2)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1 # j+1 instead of j since previous_row and current_row are one character longer\n",
    "            deletions = current_row[j] + 1       # than s2\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    \n",
    "    return previous_row[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cпелчекер по Левенштейну слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def levenshtein_spell_checker(test_word):\n",
    "    print(\"checking: \" + test_word)\n",
    "\n",
    "    leve = lambda word: levenshtein(word, test_word)\n",
    "    \n",
    "    results = list(map(leve, list(DICTIONARY.keys())))\n",
    "    minimum = min(results)\n",
    "    \n",
    "    siblings = []\n",
    "\n",
    "    for i, word in enumerate(DICTIONARY):\n",
    "        if results[i] == minimum or (results[i] == 1 if minimum else False):\n",
    "            siblings.append(word)\n",
    "            print(\"    debug| word: %s  counts: %s  dist: %s\" % (word, DICTIONARY.get(word), results[i]))\n",
    "            \n",
    "    best_match = most_frequent(siblings) \n",
    "    print(\"  result: \" + best_match)\n",
    "    return best_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Тестируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking: и\n",
      "    debug| word: и  counts: 402766  dist: 0\n",
      "  result: и\n"
     ]
    }
   ],
   "source": [
    "levenshtein_spell_checker(X_test[4]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking: оцинил\n",
      "    debug| word: оценил  counts: 437  dist: 1\n",
      "  result: оценил\n"
     ]
    }
   ],
   "source": [
    "levenshtein_spell_checker(X_test[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking: самалетав\n",
      "    debug| word: сабалета  counts: 6  dist: 2\n",
      "    debug| word: самолетам  counts: 81  dist: 2\n",
      "    debug| word: самолета  counts: 2995  dist: 2\n",
      "    debug| word: самолетов  counts: 2654  dist: 2\n",
      "    debug| word: самолетах  counts: 244  dist: 2\n",
      "  result: самолета\n"
     ]
    }
   ],
   "source": [
    "levenshtein_spell_checker(X_test[3]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cпелчекер путем генерации ближайших слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LOWER_CASE_LETTERS = {u'а', u'б', u'в', u'г', u'д', u'е', u'ё', u'ж',\n",
    "                      u'з', u'и', u'й', u'к', u'л', u'м', u'н', u'о',\n",
    "                      u'п', u'р', u'с', u'т', u'у', u'ф', u'х', u'ц',\n",
    "                      u'ч', u'ш', u'щ', u'ъ', u'ы', u'ь', u'э', u'ю', u'я',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(LOWER_CASE_LETTERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_by_substitutions(word):\n",
    "    new_words = []\n",
    "    \n",
    "    for i in range(len(word)):\n",
    "        for l in LOWER_CASE_LETTERS - set([word[i]]):\n",
    "            new_word = word[:i] + l + word[i+1:]\n",
    "            new_words.append(new_word)\n",
    "\n",
    "#     print(len(new_words))\n",
    "    \n",
    "    return new_words\n",
    "\n",
    "\n",
    "def generate_by_deletions(word):\n",
    "    new_words = []\n",
    "    \n",
    "    for i in range(len(word)):\n",
    "        new_word = word[:i] + word[i+1:]\n",
    "        new_words.append(new_word)\n",
    "\n",
    "#     print(len(new_words))\n",
    "    \n",
    "    return new_words\n",
    "    \n",
    "\n",
    "def generate_by_insertions(word):\n",
    "    new_words = []\n",
    "\n",
    "    for i in range(len(word)):\n",
    "        for l in LOWER_CASE_LETTERS:\n",
    "            new_word = word[:i] + l + word[i:]\n",
    "            new_words.append(new_word)\n",
    "            \n",
    "#     print(len(new_words))\n",
    "    \n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_words(test_word):\n",
    "    gen_by_substitutions = generate_by_substitutions(test_word)\n",
    "    gen_by_deletions = generate_by_deletions(test_word)\n",
    "    gen_by_insertions = generate_by_insertions(test_word)\n",
    "    \n",
    "    generated_words = gen_by_substitutions + gen_by_deletions + gen_by_insertions\n",
    "\n",
    "    return generated_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generative_spell_checker(test_word):\n",
    "    print(\"checking: \" + test_word)\n",
    "    if len(test_word) < 2:\n",
    "        print(\"  result: \" + test_word)\n",
    "        return test_word\n",
    "    \n",
    "    generated_words = generate_words(test_word)\n",
    "    generated_words += [test_word]\n",
    "    generated_words_cleaned = [word for word in generated_words if word in DICTIONARY]\n",
    "\n",
    "    if not len(generated_words_cleaned):\n",
    "        generated_words = list(chain.from_iterable([generate_words(word) for word in generated_words]))\n",
    "        generated_words += [test_word]\n",
    "        generated_words_cleaned = [word for word in generated_words if word in DICTIONARY]\n",
    "        \n",
    "    print(\"    debug| words: %s\" % (generated_words_cleaned))\n",
    "    \n",
    "    best_match = most_frequent(generated_words_cleaned)\n",
    "    print(\"  result: \" + best_match)\n",
    "    print()\n",
    "    return best_match\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Тестируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking: оцинил\n",
      "    debug| words: ['оценил']\n",
      "  result: оценил\n",
      "\n",
      "checking: роботу\n",
      "    debug| words: ['работу', 'робота', 'роботы', 'роботе', 'робот', 'роботу']\n",
      "  result: работу\n",
      "\n",
      "checking: новвых\n",
      "    debug| words: ['новых', 'новых']\n",
      "  result: новых\n",
      "\n",
      "checking: самалетав\n",
      "    debug| words: ['сабалета', 'самолетов', 'самолетам', 'самолетах', 'самолета', 'самолетов', 'самолетам', 'самолетах', 'сабалета', 'самолета']\n",
      "  result: самолета\n",
      "\n",
      "checking: и\n",
      "  result: и\n",
      "checking: виртолтов\n",
      "    debug| words: ['вертолётов', 'вертолетов', 'вертолётов', 'вертолетов']\n",
      "  result: вертолетов\n",
      "\n",
      "checking: в\n",
      "  result: в\n",
      "checking: сирийи\n",
      "    debug| words: ['сирицки', 'сирицки', 'сирии', 'сирии', 'сирии', 'сирии', 'сирии', 'сирии']\n",
      "  result: сирии\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for test_word in X_test:\n",
    "    generative_spell_checker(test_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
