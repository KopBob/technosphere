{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = []\n",
    "with open(\"./gold/gold.txt\") as f:\n",
    "    texts = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_label</th>\n",
       "      <th>_pos</th>\n",
       "      <th>_text_num</th>\n",
       "      <th>dist_to_next</th>\n",
       "      <th>dist_to_prev</th>\n",
       "      <th>is_next_uppercase</th>\n",
       "      <th>is_prev_uppercase</th>\n",
       "      <th>len_of_next_word</th>\n",
       "      <th>len_of_prev_word</th>\n",
       "      <th>next_punctuation_kind</th>\n",
       "      <th>prev_punctuation_kind</th>\n",
       "      <th>punctuation_kind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>219</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>.</td>\n",
       "      <td>|</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>393</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>403</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _label  _pos  _text_num  dist_to_next  dist_to_prev  is_next_uppercase  \\\n",
       "0      -1   218          0            62           219                  1   \n",
       "1       1   280          0             9            62                  1   \n",
       "2      -1   289          0           104             9                  1   \n",
       "3      -1   393          0            10           104                  1   \n",
       "4       1   403          0             3            10                  0   \n",
       "\n",
       "   is_prev_uppercase  len_of_next_word  len_of_prev_word  \\\n",
       "0                  1                 2                 8   \n",
       "1                  1                 7                 1   \n",
       "2                  1                 6                 7   \n",
       "3                  0                 1                 6   \n",
       "4                  0                 1                 1   \n",
       "\n",
       "  next_punctuation_kind prev_punctuation_kind punctuation_kind  \n",
       "0                     .                     |                .  \n",
       "1                     .                     .                .  \n",
       "2                     .                     .                .  \n",
       "3                     .                     .                .  \n",
       "4                     .                     .                .  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./dataset2.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = ['dist_to_next', 'dist_to_prev',\n",
    "       'is_next_uppercase', 'is_prev_uppercase', 'len_of_next_word',\n",
    "       'len_of_prev_word', 'next_punctuation_kind', 'prev_punctuation_kind',\n",
    "       'punctuation_kind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dict = df[features].T.to_dict().values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot-Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transformer = DictVectorizer(sparse=False)\n",
    "X = transformer.fit_transform(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./gold/models/transformer']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(transformer, \"./gold/models/transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 15)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = df[\"_label\"].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=241)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((216,), (93,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_params(estimator, params, X, y, scoring=\"roc_auc\", cv=5):\n",
    "    print(estimator, params)\n",
    "    gsc = GridSearchCV(estimator, params, cv=cv, scoring=scoring)\n",
    "    gsc.fit(X, y)\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(gsc.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    for params, mean_score, scores in gsc.grid_scores_:\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean_score, scores.std() * 2, params))\n",
    "    print()\n",
    "    return gsc.best_estimator_, gsc.best_params_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evalute_scores(model_clf, _X_train, _X_test, _y_train, _y_test):\n",
    "    model_clf.fit(_X_train, _y_train)\n",
    "    _y_pred = model_clf.predict(_X_test)\n",
    "    print(classification_report(_y_test, _y_pred))\n",
    "    print(accuracy_score(_y_test, _y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model_object, params_search_grid, _X_train, _X_test, _y_train, _y_test):\n",
    "    model_clf, model_params = search_params(estimator=model_object, params=params_search_grid,\n",
    "                                            X=_X_train, y=_y_train,\n",
    "                                            scoring=\"accuracy\", cv=3)\n",
    "    \n",
    "    evalute_scores(model_clf, _X_train, _X_test, _y_train, _y_test)\n",
    "    \n",
    "    return model_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0), {'penalty': ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]})\n",
      "Best parameters set found on development set:\n",
      "()\n",
      "{'penalty': 'l2', 'C': 1.0}\n",
      "()\n",
      "Grid scores on development set:\n",
      "()\n",
      "0.606 (+/-0.007) for {'penalty': 'l1', 'C': 0.001}\n",
      "0.630 (+/-0.034) for {'penalty': 'l2', 'C': 0.001}\n",
      "0.606 (+/-0.007) for {'penalty': 'l1', 'C': 0.01}\n",
      "0.806 (+/-0.048) for {'penalty': 'l2', 'C': 0.01}\n",
      "0.875 (+/-0.041) for {'penalty': 'l1', 'C': 0.1}\n",
      "0.921 (+/-0.034) for {'penalty': 'l2', 'C': 0.1}\n",
      "0.926 (+/-0.015) for {'penalty': 'l1', 'C': 1.0}\n",
      "0.940 (+/-0.014) for {'penalty': 'l2', 'C': 1.0}\n",
      "0.926 (+/-0.027) for {'penalty': 'l1', 'C': 10.0}\n",
      "0.926 (+/-0.027) for {'penalty': 'l2', 'C': 10.0}\n",
      "0.931 (+/-0.040) for {'penalty': 'l1', 'C': 100.0}\n",
      "0.931 (+/-0.040) for {'penalty': 'l2', 'C': 100.0}\n",
      "()\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       1.00      0.97      0.98        60\n",
      "          1       0.94      1.00      0.97        33\n",
      "\n",
      "avg / total       0.98      0.98      0.98        93\n",
      "\n",
      "0.978494623656\n"
     ]
    }
   ],
   "source": [
    "model_1_params_grid = {\n",
    "    \"penalty\": ['l1', 'l2'],\n",
    "    \"C\": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "}\n",
    "\n",
    "model_1 = evaluate_model(LogisticRegression(), model_1_params_grid,\n",
    "              X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.98      0.93      0.96        60\n",
      "          1       0.89      0.97      0.93        33\n",
      "\n",
      "avg / total       0.95      0.95      0.95        93\n",
      "\n",
      "0.94623655914\n"
     ]
    }
   ],
   "source": [
    "model_1_cl = CalibratedClassifierCV(model_1)\n",
    "evalute_scores(model_1_cl, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2. AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None) {'learning_rate': [0.1, 0.3, 0.6, 0.8, 1.0], 'n_estimators': [50, 100, 150, 200]}\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_estimators': 50, 'learning_rate': 0.1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.949 (+/-0.048) for {'n_estimators': 50, 'learning_rate': 0.1}\n",
      "0.949 (+/-0.027) for {'n_estimators': 100, 'learning_rate': 0.1}\n",
      "0.940 (+/-0.048) for {'n_estimators': 150, 'learning_rate': 0.1}\n",
      "0.940 (+/-0.048) for {'n_estimators': 200, 'learning_rate': 0.1}\n",
      "0.949 (+/-0.035) for {'n_estimators': 50, 'learning_rate': 0.3}\n",
      "0.940 (+/-0.048) for {'n_estimators': 100, 'learning_rate': 0.3}\n",
      "0.944 (+/-0.039) for {'n_estimators': 150, 'learning_rate': 0.3}\n",
      "0.940 (+/-0.047) for {'n_estimators': 200, 'learning_rate': 0.3}\n",
      "0.944 (+/-0.039) for {'n_estimators': 50, 'learning_rate': 0.6}\n",
      "0.944 (+/-0.060) for {'n_estimators': 100, 'learning_rate': 0.6}\n",
      "0.935 (+/-0.056) for {'n_estimators': 150, 'learning_rate': 0.6}\n",
      "0.917 (+/-0.022) for {'n_estimators': 200, 'learning_rate': 0.6}\n",
      "0.935 (+/-0.052) for {'n_estimators': 50, 'learning_rate': 0.8}\n",
      "0.940 (+/-0.069) for {'n_estimators': 100, 'learning_rate': 0.8}\n",
      "0.931 (+/-0.044) for {'n_estimators': 150, 'learning_rate': 0.8}\n",
      "0.931 (+/-0.044) for {'n_estimators': 200, 'learning_rate': 0.8}\n",
      "0.931 (+/-0.039) for {'n_estimators': 50, 'learning_rate': 1.0}\n",
      "0.926 (+/-0.091) for {'n_estimators': 100, 'learning_rate': 1.0}\n",
      "0.921 (+/-0.056) for {'n_estimators': 150, 'learning_rate': 1.0}\n",
      "0.926 (+/-0.033) for {'n_estimators': 200, 'learning_rate': 1.0}\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.98      0.97      0.97        60\n",
      "          1       0.94      0.97      0.96        33\n",
      "\n",
      "avg / total       0.97      0.97      0.97        93\n",
      "\n",
      "0.967741935484\n"
     ]
    }
   ],
   "source": [
    "model_2_params_grid = {\n",
    "    \"n_estimators\": list(range(50, 201, 50)),\n",
    "    \"learning_rate\": [0.1, 0.3, 0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "model_2 = evaluate_model(AdaBoostClassifier(), model_2_params_grid,\n",
    "              X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       1.00      0.97      0.98        60\n",
      "          1       0.94      1.00      0.97        33\n",
      "\n",
      "avg / total       0.98      0.98      0.98        93\n",
      "\n",
      "0.978494623656\n"
     ]
    }
   ],
   "source": [
    "model_2_cl = CalibratedClassifierCV(model_2)\n",
    "evalute_scores(model_2_cl, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3. Gradien Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False) {'learning_rate': [0.1, 0.4, 0.7, 1.0], 'n_estimators': [50, 100, 150, 200], 'max_depth': [1, 2, 3, 4, 5, 6]}\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_estimators': 50, 'learning_rate': 0.4, 'max_depth': 1}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.944 (+/-0.024) for {'n_estimators': 50, 'learning_rate': 0.1, 'max_depth': 1}\n",
      "0.940 (+/-0.036) for {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 1}\n",
      "0.940 (+/-0.036) for {'n_estimators': 150, 'learning_rate': 0.1, 'max_depth': 1}\n",
      "0.944 (+/-0.041) for {'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 1}\n",
      "0.935 (+/-0.049) for {'n_estimators': 50, 'learning_rate': 0.1, 'max_depth': 2}\n",
      "0.926 (+/-0.048) for {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 2}\n",
      "0.921 (+/-0.036) for {'n_estimators': 150, 'learning_rate': 0.1, 'max_depth': 2}\n",
      "0.921 (+/-0.036) for {'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 2}\n",
      "0.931 (+/-0.046) for {'n_estimators': 50, 'learning_rate': 0.1, 'max_depth': 3}\n",
      "0.917 (+/-0.046) for {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 3}\n",
      "0.921 (+/-0.036) for {'n_estimators': 150, 'learning_rate': 0.1, 'max_depth': 3}\n",
      "0.912 (+/-0.048) for {'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 3}\n",
      "0.917 (+/-0.060) for {'n_estimators': 50, 'learning_rate': 0.1, 'max_depth': 4}\n",
      "0.912 (+/-0.080) for {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 4}\n",
      "0.931 (+/-0.060) for {'n_estimators': 150, 'learning_rate': 0.1, 'max_depth': 4}\n",
      "0.921 (+/-0.058) for {'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 4}\n",
      "0.907 (+/-0.047) for {'n_estimators': 50, 'learning_rate': 0.1, 'max_depth': 5}\n",
      "0.917 (+/-0.060) for {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 5}\n",
      "0.917 (+/-0.060) for {'n_estimators': 150, 'learning_rate': 0.1, 'max_depth': 5}\n",
      "0.912 (+/-0.058) for {'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 5}\n",
      "0.894 (+/-0.013) for {'n_estimators': 50, 'learning_rate': 0.1, 'max_depth': 6}\n",
      "0.903 (+/-0.020) for {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 6}\n",
      "0.903 (+/-0.020) for {'n_estimators': 150, 'learning_rate': 0.1, 'max_depth': 6}\n",
      "0.907 (+/-0.024) for {'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 6}\n",
      "0.949 (+/-0.027) for {'n_estimators': 50, 'learning_rate': 0.4, 'max_depth': 1}\n",
      "0.949 (+/-0.048) for {'n_estimators': 100, 'learning_rate': 0.4, 'max_depth': 1}\n",
      "0.940 (+/-0.036) for {'n_estimators': 150, 'learning_rate': 0.4, 'max_depth': 1}\n",
      "0.931 (+/-0.024) for {'n_estimators': 200, 'learning_rate': 0.4, 'max_depth': 1}\n",
      "0.921 (+/-0.036) for {'n_estimators': 50, 'learning_rate': 0.4, 'max_depth': 2}\n",
      "0.917 (+/-0.046) for {'n_estimators': 100, 'learning_rate': 0.4, 'max_depth': 2}\n",
      "0.926 (+/-0.015) for {'n_estimators': 150, 'learning_rate': 0.4, 'max_depth': 2}\n",
      "0.912 (+/-0.035) for {'n_estimators': 200, 'learning_rate': 0.4, 'max_depth': 2}\n",
      "0.917 (+/-0.046) for {'n_estimators': 50, 'learning_rate': 0.4, 'max_depth': 3}\n",
      "0.917 (+/-0.060) for {'n_estimators': 100, 'learning_rate': 0.4, 'max_depth': 3}\n",
      "0.917 (+/-0.060) for {'n_estimators': 150, 'learning_rate': 0.4, 'max_depth': 3}\n",
      "0.926 (+/-0.035) for {'n_estimators': 200, 'learning_rate': 0.4, 'max_depth': 3}\n",
      "0.917 (+/-0.060) for {'n_estimators': 50, 'learning_rate': 0.4, 'max_depth': 4}\n",
      "0.926 (+/-0.073) for {'n_estimators': 100, 'learning_rate': 0.4, 'max_depth': 4}\n",
      "0.917 (+/-0.046) for {'n_estimators': 150, 'learning_rate': 0.4, 'max_depth': 4}\n",
      "0.921 (+/-0.070) for {'n_estimators': 200, 'learning_rate': 0.4, 'max_depth': 4}\n",
      "0.907 (+/-0.070) for {'n_estimators': 50, 'learning_rate': 0.4, 'max_depth': 5}\n",
      "0.903 (+/-0.069) for {'n_estimators': 100, 'learning_rate': 0.4, 'max_depth': 5}\n",
      "0.903 (+/-0.069) for {'n_estimators': 150, 'learning_rate': 0.4, 'max_depth': 5}\n",
      "0.907 (+/-0.070) for {'n_estimators': 200, 'learning_rate': 0.4, 'max_depth': 5}\n",
      "0.889 (+/-0.044) for {'n_estimators': 50, 'learning_rate': 0.4, 'max_depth': 6}\n",
      "0.894 (+/-0.033) for {'n_estimators': 100, 'learning_rate': 0.4, 'max_depth': 6}\n",
      "0.889 (+/-0.024) for {'n_estimators': 150, 'learning_rate': 0.4, 'max_depth': 6}\n",
      "0.889 (+/-0.024) for {'n_estimators': 200, 'learning_rate': 0.4, 'max_depth': 6}\n",
      "0.940 (+/-0.048) for {'n_estimators': 50, 'learning_rate': 0.7, 'max_depth': 1}\n",
      "0.935 (+/-0.013) for {'n_estimators': 100, 'learning_rate': 0.7, 'max_depth': 1}\n",
      "0.931 (+/-0.024) for {'n_estimators': 150, 'learning_rate': 0.7, 'max_depth': 1}\n",
      "0.935 (+/-0.013) for {'n_estimators': 200, 'learning_rate': 0.7, 'max_depth': 1}\n",
      "0.917 (+/-0.041) for {'n_estimators': 50, 'learning_rate': 0.7, 'max_depth': 2}\n",
      "0.912 (+/-0.036) for {'n_estimators': 100, 'learning_rate': 0.7, 'max_depth': 2}\n",
      "0.912 (+/-0.036) for {'n_estimators': 150, 'learning_rate': 0.7, 'max_depth': 2}\n",
      "0.912 (+/-0.036) for {'n_estimators': 200, 'learning_rate': 0.7, 'max_depth': 2}\n",
      "0.912 (+/-0.052) for {'n_estimators': 50, 'learning_rate': 0.7, 'max_depth': 3}\n",
      "0.917 (+/-0.082) for {'n_estimators': 100, 'learning_rate': 0.7, 'max_depth': 3}\n",
      "0.921 (+/-0.086) for {'n_estimators': 150, 'learning_rate': 0.7, 'max_depth': 3}\n",
      "0.921 (+/-0.070) for {'n_estimators': 200, 'learning_rate': 0.7, 'max_depth': 3}\n",
      "0.903 (+/-0.060) for {'n_estimators': 50, 'learning_rate': 0.7, 'max_depth': 4}\n",
      "0.921 (+/-0.047) for {'n_estimators': 100, 'learning_rate': 0.7, 'max_depth': 4}\n",
      "0.912 (+/-0.048) for {'n_estimators': 150, 'learning_rate': 0.7, 'max_depth': 4}\n",
      "0.917 (+/-0.060) for {'n_estimators': 200, 'learning_rate': 0.7, 'max_depth': 4}\n",
      "0.898 (+/-0.095) for {'n_estimators': 50, 'learning_rate': 0.7, 'max_depth': 5}\n",
      "0.894 (+/-0.107) for {'n_estimators': 100, 'learning_rate': 0.7, 'max_depth': 5}\n",
      "0.907 (+/-0.086) for {'n_estimators': 150, 'learning_rate': 0.7, 'max_depth': 5}\n",
      "0.903 (+/-0.099) for {'n_estimators': 200, 'learning_rate': 0.7, 'max_depth': 5}\n",
      "0.884 (+/-0.049) for {'n_estimators': 50, 'learning_rate': 0.7, 'max_depth': 6}\n",
      "0.898 (+/-0.052) for {'n_estimators': 100, 'learning_rate': 0.7, 'max_depth': 6}\n",
      "0.889 (+/-0.039) for {'n_estimators': 150, 'learning_rate': 0.7, 'max_depth': 6}\n",
      "0.894 (+/-0.086) for {'n_estimators': 200, 'learning_rate': 0.7, 'max_depth': 6}\n",
      "0.940 (+/-0.026) for {'n_estimators': 50, 'learning_rate': 1.0, 'max_depth': 1}\n",
      "0.931 (+/-0.024) for {'n_estimators': 100, 'learning_rate': 1.0, 'max_depth': 1}\n",
      "0.935 (+/-0.013) for {'n_estimators': 150, 'learning_rate': 1.0, 'max_depth': 1}\n",
      "0.926 (+/-0.036) for {'n_estimators': 200, 'learning_rate': 1.0, 'max_depth': 1}\n",
      "0.907 (+/-0.028) for {'n_estimators': 50, 'learning_rate': 1.0, 'max_depth': 2}\n",
      "0.912 (+/-0.015) for {'n_estimators': 100, 'learning_rate': 1.0, 'max_depth': 2}\n",
      "0.907 (+/-0.028) for {'n_estimators': 150, 'learning_rate': 1.0, 'max_depth': 2}\n",
      "0.907 (+/-0.028) for {'n_estimators': 200, 'learning_rate': 1.0, 'max_depth': 2}\n",
      "0.926 (+/-0.035) for {'n_estimators': 50, 'learning_rate': 1.0, 'max_depth': 3}\n",
      "0.931 (+/-0.024) for {'n_estimators': 100, 'learning_rate': 1.0, 'max_depth': 3}\n",
      "0.940 (+/-0.014) for {'n_estimators': 150, 'learning_rate': 1.0, 'max_depth': 3}\n",
      "0.931 (+/-0.024) for {'n_estimators': 200, 'learning_rate': 1.0, 'max_depth': 3}\n",
      "0.907 (+/-0.049) for {'n_estimators': 50, 'learning_rate': 1.0, 'max_depth': 4}\n",
      "0.912 (+/-0.035) for {'n_estimators': 100, 'learning_rate': 1.0, 'max_depth': 4}\n",
      "0.926 (+/-0.035) for {'n_estimators': 150, 'learning_rate': 1.0, 'max_depth': 4}\n",
      "0.912 (+/-0.025) for {'n_estimators': 200, 'learning_rate': 1.0, 'max_depth': 4}\n",
      "0.926 (+/-0.027) for {'n_estimators': 50, 'learning_rate': 1.0, 'max_depth': 5}\n",
      "0.921 (+/-0.058) for {'n_estimators': 100, 'learning_rate': 1.0, 'max_depth': 5}\n",
      "0.921 (+/-0.036) for {'n_estimators': 150, 'learning_rate': 1.0, 'max_depth': 5}\n",
      "0.926 (+/-0.048) for {'n_estimators': 200, 'learning_rate': 1.0, 'max_depth': 5}\n",
      "0.903 (+/-0.082) for {'n_estimators': 50, 'learning_rate': 1.0, 'max_depth': 6}\n",
      "0.907 (+/-0.048) for {'n_estimators': 100, 'learning_rate': 1.0, 'max_depth': 6}\n",
      "0.889 (+/-0.060) for {'n_estimators': 150, 'learning_rate': 1.0, 'max_depth': 6}\n",
      "0.907 (+/-0.065) for {'n_estimators': 200, 'learning_rate': 1.0, 'max_depth': 6}\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.95      0.98      0.97        60\n",
      "          1       0.97      0.91      0.94        33\n",
      "\n",
      "avg / total       0.96      0.96      0.96        93\n",
      "\n",
      "0.956989247312\n"
     ]
    }
   ],
   "source": [
    "model_3_params_grid = {\n",
    "    \"n_estimators\": list(range(50, 201, 50)),\n",
    "    \"max_depth\": [1, 2, 3, 4, 5, 6],\n",
    "    \"learning_rate\": [0.1, 0.4, 0.7, 1.0]\n",
    "}\n",
    "\n",
    "model_3 = evaluate_model(GradientBoostingClassifier(), model_3_params_grid,\n",
    "              X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.98      0.98      0.98        60\n",
      "          1       0.97      0.97      0.97        33\n",
      "\n",
      "avg / total       0.98      0.98      0.98        93\n",
      "\n",
      "0.978494623656\n"
     ]
    }
   ],
   "source": [
    "model_3_cl = CalibratedClassifierCV(model_3)\n",
    "evalute_scores(model_3_cl, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) {'C': [1.0, 10.0, 100.0], 'kernel': ('linear', 'rbf')}\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10.0, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.907 (+/-0.036) for {'C': 1.0, 'kernel': 'linear'}\n",
      "0.694 (+/-0.072) for {'C': 1.0, 'kernel': 'rbf'}\n",
      "0.921 (+/-0.013) for {'C': 10.0, 'kernel': 'linear'}\n",
      "0.694 (+/-0.050) for {'C': 10.0, 'kernel': 'rbf'}\n",
      "0.917 (+/-0.024) for {'C': 100.0, 'kernel': 'linear'}\n",
      "0.694 (+/-0.050) for {'C': 100.0, 'kernel': 'rbf'}\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       1.00      0.93      0.97        60\n",
      "          1       0.89      1.00      0.94        33\n",
      "\n",
      "avg / total       0.96      0.96      0.96        93\n",
      "\n",
      "0.956989247312\n"
     ]
    }
   ],
   "source": [
    "model_4_params_grid = {\n",
    "    \"kernel\": ('linear', 'rbf'),\n",
    "    \"C\": [1.0, 10.0, 100.0]\n",
    "}\n",
    "\n",
    "model_4 = evaluate_model(SVC(), model_4_params_grid,\n",
    "              X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       1.00      0.97      0.98        60\n",
      "          1       0.94      1.00      0.97        33\n",
      "\n",
      "avg / total       0.98      0.98      0.98        93\n",
      "\n",
      "0.978494623656\n"
     ]
    }
   ],
   "source": [
    "model_4_cl = CalibratedClassifierCV(model_4)\n",
    "evalute_scores(model_4_cl, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./gold/models/model_1',\n",
       " './gold/models/model_1_01.npy',\n",
       " './gold/models/model_1_02.npy',\n",
       " './gold/models/model_1_03.npy']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model_1, \"./gold/models/model_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
